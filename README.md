# AirDataPipeline

<!-- Badges das principais tecnologias -->
<p align="center">
  <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white" alt="Python"/>
  <img src="https://img.shields.io/badge/Apache%20Airflow-017CEE?style=for-the-badge&logo=Apache%20Airflow&logoColor=whiâ””â”€â”€ dbt_project/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ staging/        # Modelos de preparaÃ§Ã£o dos dados
â”‚   â”‚   â”‚   â””â”€â”€ stg_enriched_headlines.sql # Dados limpos + classificaÃ§Ãµes
â”‚   â”‚   â””â”€â”€ gold/           # MÃ©tricas analÃ­ticas finais
â”‚   â”‚       â”œâ”€â”€ daily_sentiment_analysis.sql # AgregaÃ§Ã£o de sentimentos
â”‚   â”‚       â””â”€â”€ daily_category_analysis.sql  # AgregaÃ§Ã£o por categoria (NOVO)alt="Apache Airflow"/>
  <img src="https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white" alt="Docker"/>
  <img src="https://img.shields.io/badge/OpenAI-412991?style=for-the-badge&logo=openai&logoColor=white" alt="OpenAI"/>
  <img src="https://img.shields.io/badge/PostgreSQL-316192?style=for-the-badge&logo=postgresql&logoColor=white" alt="PostgreSQL"/>
  <img src="https://img.shields.io/badge/DBT-FF694B?style=for-the-badge&logo=dbt&logoColor=white" alt="DBT"/>
  <img src="https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white" alt="Streamlit"/>
  <img src="https://img.shields.io/badge/ETL-FF6B35?style=for-the-badge&logo=databricks&logoColor=white" alt="ETL Pipeline"/>
</p>
 

Um pipeline completo de Engenharia de Dados para coleta, processamento e visualizaÃ§Ã£o de notÃ­cias do portal G1, implementado com as principais ferramentas do mercado.

## ğŸ“‹ Acompanhamento do Desenvolvimento

Para acompanhar o fluxo completo de desenvolvimento, execuÃ§Ã£o e todas as tarefas realizadas neste projeto, acesse:

**[ğŸ”— Trello - Projeto Engenharia de Dados 01](https://trello.com/b/JTQZjq00/projeto-eng-dados01)**

## ğŸ¯ VisÃ£o Geral

Este projeto demonstra a implementaÃ§Ã£o de um pipeline de dados moderno (Data Lakehouse) seguindo a arquitetura **Bronze â†’ Silver â†’ Gold**, com orquestraÃ§Ã£o automatizada e visualizaÃ§Ã£o interativa.

### Arquitetura do Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web Scraping  â”‚â”€â”€â”€â–¶â”‚   Airflow    â”‚â”€â”€â”€â–¶â”‚ PostgreSQL  â”‚â”€â”€â”€â–¶â”‚  LLM AI      â”‚â”€â”€â”€â–¶â”‚     DBT      â”‚â”€â”€â”€â–¶â”‚  Streamlit   â”‚
â”‚     (G1)        â”‚    â”‚ (OrquestraÃ§Ã£o)â”‚   â”‚  (Bronze)   â”‚    â”‚(Enriquecimento)â”‚   â”‚(Silver/Gold) â”‚    â”‚ (Dashboard)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                      â”‚
                                                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                              â”‚ â€¢ Sentimento â”‚
                                                              â”‚ â€¢ Categoria  â”‚
                                                              â”‚ â€¢ ConfianÃ§a  â”‚
                                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ—ï¸ Componentes da Arquitetura

### ğŸ“° **Fonte de Dados (Web Scraping)**
**Nosso fornecedor de matÃ©ria-prima**

- **Alvo**: Portal G1 (https://g1.globo.com/)
- **Tecnologia**: Python + Playwright (para conteÃºdo dinÃ¢mico) / BeautifulSoup + Requests (para conteÃºdo estÃ¡tico)
- **Dados coletados**: Manchetes, links, timestamp de coleta
- **FrequÃªncia**: Agendada via Airflow
- **LocalizaÃ§Ã£o**: `scripts/scraper.py`

### ğŸ§  **Orquestrador (Apache Airflow)**
**O "cÃ©rebro" da operaÃ§Ã£o**

- **FunÃ§Ã£o**: AutomatizaÃ§Ã£o e agendamento das tarefas
- **Recursos**: 
  - ExecuÃ§Ã£o agendada (ex: todos os dias Ã s 8h)
  - Monitoramento de falhas e retries
  - Logs detalhados de execuÃ§Ã£o
  - Interface web para acompanhamento
- **LocalizaÃ§Ã£o**: `dags/`

### ğŸ›ï¸ **Banco de Dados (PostgreSQL)**
**Nosso "armazÃ©m" - Bronze Layer**

- **FunÃ§Ã£o**: Armazenamento dos dados brutos
- **CaracterÃ­sticas**:
  - Dados exatamente como coletados
  - Sem transformaÃ§Ãµes
  - HistÃ³rico completo preservado
- **ConfiguraÃ§Ã£o**: Docker container

### ğŸ¤– **Enriquecimento com IA (LLM)**
**Nossa "inteligÃªncia analÃ­tica"**

- **FunÃ§Ã£o**: AnÃ¡lise e classificaÃ§Ã£o automÃ¡tica das manchetes
- **Tecnologias**: OpenAI GPT / Anthropic Claude / Modelos locais (Ollama)
- **Processamento**:
  - **AnÃ¡lise de Sentimento**: Classifica cada manchete como:
    - ğŸŸ¢ **Positiva**: NotÃ­cias otimistas, conquistas, boas notÃ­cias
    - ğŸ”´ **Negativa**: TragÃ©dias, conflitos, problemas sociais
    - âšª **Neutra**: InformaÃ§Ãµes factuais, declaraÃ§Ãµes, eventos neutros
  - **CategorizaÃ§Ã£o**: Classifica por tÃ³picos:
    - ğŸ›ï¸ **PolÃ­tica**: Governo, eleiÃ§Ãµes, polÃ­ticas pÃºblicas
    - âš½ **Esportes**: Futebol, olimpÃ­adas, competiÃ§Ãµes
    - ğŸ’» **Tecnologia**: InovaÃ§Ãµes, ciÃªncia, digital
    - ğŸ’° **Economia**: Mercado, inflaÃ§Ã£o, negÃ³cios
    - ğŸ­ **Cultura**: Arte, entretenimento, celebridades
    - ğŸ¥ **SaÃºde**: Medicina, epidemias, bem-estar
    - ğŸŒ **Internacional**: NotÃ­cias globais, diplomacia
    - âš–ï¸ **JustiÃ§a**: Crimes, tribunais, legislaÃ§Ã£o
- **Posicionamento**: Entre Bronze Layer (dados brutos) e Silver Layer (dados limpos)
- **BenefÃ­cios**:
  - AutomaÃ§Ã£o de classificaÃ§Ã£o manual
  - AnÃ¡lises de tendÃªncias de sentimento
  - SegmentaÃ§Ã£o inteligente de conteÃºdo
  - Insights sobre padrÃµes noticiosos

### âš™ï¸ **Ferramenta de TransformaÃ§Ã£o (DBT)**
**Nossa "linha de beneficiamento"**

- **Bronze â†’ Silver**: Limpeza, padronizaÃ§Ã£o + dados enriquecidos pela IA
- **Silver â†’ Gold**: Modelagem analÃ­tica e agregaÃ§Ãµes por sentimento/categoria
- **Tecnologia**: SQL puro
- **BenefÃ­cios**:
  - Versionamento de transformaÃ§Ãµes
  - Testes de qualidade de dados
  - DocumentaÃ§Ã£o automÃ¡tica
  - MÃ©tricas analÃ­ticas avanÃ§adas com IA
- **LocalizaÃ§Ã£o**: `dbt_project/`

#### Modelos DBT Implementados

O DBT organiza as transformaÃ§Ãµes em trÃªs camadas principais:

1. **Bronze** (Dados brutos):
   - `raw_headlines`: Carrega os dados brutos das manchetes do G1
   - `raw_enriched_headlines`: Dados brutos com enriquecimento de IA

2. **Silver** (Dados limpos):
   - `stg_enriched_headlines`: Dados limpos + classificaÃ§Ãµes de IA

3. **Gold** (Camada analÃ­tica):
   - `daily_sentiment_analysis`: AgregaÃ§Ã£o diÃ¡ria de sentimentos
   - `daily_category_analysis`: AgregaÃ§Ã£o diÃ¡ria por categoria (NOVO)

#### Como Executar o DBT

Para configurar e executar as transformaÃ§Ãµes DBT:

```bash
# Navegue atÃ© o diretÃ³rio do projeto DBT
cd dbt_project

# Verifique se as conexÃµes estÃ£o configuradas corretamente
dbt debug

# Execute todos os modelos
dbt run

# Execute modelos especÃ­ficos
dbt run --models +silver.enriched_headlines+

# Execute modelos por tag
dbt run --models tag:daily

# Gere documentaÃ§Ã£o
dbt docs generate
dbt docs serve
```

### ğŸ“Š **Camada de VisualizaÃ§Ã£o (Streamlit)**
**Nossa "vitrine"**

- **FunÃ§Ã£o**: Dashboard interativo com insights de IA
- **Recursos**:
  - VisualizaÃ§Ã£o dos dados da camada Gold
  - **AnÃ¡lises de Sentimento**: DistribuiÃ§Ã£o temporal de sentimentos
  - **Dashboard de Categorias**: Volume por tÃ³pico e tendÃªncias
  - **MÃ©tricas de IA**: PrecisÃ£o da classificaÃ§Ã£o e confianÃ§a
  - **Alertas**: DetecÃ§Ã£o de picos de sentimento negativo
  
#### ğŸ†• Novas Funcionalidades no Dashboard (VersÃ£o Melhorada)

- **Interface por Abas**: OrganizaÃ§Ã£o em abas para melhor navegabilidade (EvoluÃ§Ã£o Temporal, DistribuiÃ§Ã£o por Categoria, ConfianÃ§a do Modelo, Manchetes Recentes)
- **Filtros AvanÃ§ados**: Seletores de intervalo de datas na barra lateral
- **AnÃ¡lise por Categoria**: Nova visualizaÃ§Ã£o dedicada Ã  distribuiÃ§Ã£o de categorias
  - GrÃ¡fico de barras mostrando volume por categoria
  - EvoluÃ§Ã£o temporal das principais categorias
  - Mapa de calor (heatmap) de categorias por dia
- **MÃ©tricas de ConfianÃ§a**: Nova seÃ§Ã£o mostrando a confianÃ§a do modelo de IA
  - VisualizaÃ§Ã£o da confianÃ§a mÃ©dia por sentimento
  - Histograma de distribuiÃ§Ã£o de confianÃ§a
- **VisualizaÃ§Ã£o de Manchetes Recentes**: Tabela com as Ãºltimas notÃ­cias processadas
  - Links clicÃ¡veis para as notÃ­cias originais
  - FormataÃ§Ã£o visual por sentimento (verde para positivo, vermelho para negativo)
- **Indicadores de TendÃªncia**: AnÃ¡lise comparativa mostrando evoluÃ§Ã£o do sentimento
- **VisualizaÃ§Ãµes AvanÃ§adas**: GrÃ¡ficos de Ã¡rea para proporÃ§Ã£o de sentimentos
- **EstatÃ­sticas Detalhadas**: MÃ©tricas avanÃ§adas como mÃ©dia diÃ¡ria e tendÃªncias

- **LocalizaÃ§Ã£o**: `streamlit_app/`
  - `dashboard.py`: VersÃ£o original

### ğŸ³ **Ambiente (Docker & Docker Compose)**
**Nossa "fÃ¡brica"**

- **Docker**: ContainerizaÃ§Ã£o de cada componente
- **Docker Compose**: OrquestraÃ§Ã£o de todos os serviÃ§os
- **BenefÃ­cios**:
  - Ambiente reproduzÃ­vel
  - Isolamento de dependÃªncias
  - Deploy simplificado

## ğŸš€ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### PrÃ©-requisitos

- Python 3.10+
- Docker e Docker Compose
- Git

### 1. Clone o RepositÃ³rio

```bash
git clone https://github.com/edu-data-dev/AirDataPipeline.git
cd AirDataPipeline
```

### 2. ConfiguraÃ§Ã£o do Ambiente Python

```bash
# Criar ambiente virtual
python -m venv .venv

# Ativar ambiente virtual (Linux/Mac)
source .venv/bin/activate

# Ativar ambiente virtual (Windows)
.venv\Scripts\activate

# Instalar dependÃªncias
pip install -r requirements.txt

# Instalar navegador para Playwright
python -m playwright install chromium
```

### 3. ConfiguraÃ§Ã£o do Ambiente

```bash
# Copiar arquivo de configuraÃ§Ã£o
cp .env.example .env

# Editar variÃ¡veis de ambiente conforme necessÃ¡rio
nano .env
```

## ğŸ“‹ Uso do Sistema

#### Web Scraping Engine Playwright (conteÃºdo dinÃ¢mico)
```bash
python scripts/scraper.py --engine playwright
```

**SaÃ­da**: Arquivo CSV com timestamp (`g1_headlines_playwright_YYYYMMDD_HHMMSS.csv`)

### Exemplo de Dados Coletados

```csv
title,link,source,scraped_at
"Corpo de Luis Fernando Verissimo Ã© velado na Assembleia do RS",https://g1.globo.com/rs/rio-grande-do-sul/noticia/2025/08/30/corpo-do-escritor-luis-fernando-verissimo-e-velado-na-assembleia-legislativa-em-porto-alegre.ghtml,G1,2025-08-30T18:00:06.860299
"Ã‰ #FAKE que Trump morreu; presidente Ã© visto a caminho de campo de golfe",https://g1.globo.com/fato-ou-fake/noticia/2025/08/30/e-fake-que-donald-trump-morreu-presidente-e-visto-a-caminho-de-golfe.ghtml,G1,2025-08-30T18:00:07.026369
```

### 4. Subir o Ambiente com Docker

```bash
# Construir e iniciar todos os serviÃ§os (primeira execuÃ§Ã£o)
docker-compose up --build -d

# Para execuÃ§Ãµes posteriores (sem rebuild)
docker-compose up -d

# Verificar status dos containers
docker-compose ps

# Parar todos os serviÃ§os
docker-compose down

# Parar e remover volumes (dados serÃ£o perdidos)
docker-compose down -v

# Verificar logs de um serviÃ§o especÃ­fico
docker-compose logs -f airflow_webserver
docker-compose logs -f postgres_db

# Verificar logs de todos os serviÃ§os
docker-compose logs -f
```

### 5. Executar o Dashboard Streamlit (Local)

```bash
# Ativar ambiente virtual
source .venv/bin/activate

# Navegar para o diretÃ³rio do Streamlit
cd streamlit_app

# Executar o dashboard original
streamlit run dashboard.py

```

### Interfaces de Acesso

- **Airflow**: http://localhost:8080
- **Streamlit Dashboard**: http://localhost:8501
- **PostgreSQL**: localhost:5432

## ğŸ“ Estrutura do Projeto

```
AirDataPipeline/
â”œâ”€â”€ .env.example              # Exemplo de variÃ¡veis de ambiente
â”œâ”€â”€ .gitignore               # Arquivos ignorados pelo Git
â”œâ”€â”€ requirements.txt         # DependÃªncias Python
â”œâ”€â”€ docker-compose.yml       # ConfiguraÃ§Ã£o dos containers
â”œâ”€â”€ dockerfile               # Dockerfile para construÃ§Ã£o de imagens
â”œâ”€â”€ README.md               # Este arquivo
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/                # Dados brutos coletados pelo scraper
â”œâ”€â”€ dags/
â”‚   â”œâ”€â”€ g1_scraping_dag.py  # Pipeline de coleta de notÃ­cias
â”‚   â””â”€â”€ g1_enrichement_dag.py # Pipeline de enriquecimento com IA
â”œâ”€â”€ dbt_project/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ staging/        # Modelos de preparaÃ§Ã£o dos dados
â”‚   â”‚   â””â”€â”€ gold/           # MÃ©tricas analÃ­ticas finais
â”‚   â”œâ”€â”€ tests/              # Testes de qualidade de dados
â”‚   â”œâ”€â”€ macros/             # Macros reutilizÃ¡veis
â”‚   â”œâ”€â”€ analyses/           # AnÃ¡lises ad-hoc
â”‚   â”œâ”€â”€ seeds/              # Dados de referÃªncia
â”‚   â”œâ”€â”€ snapshots/          # Snapshots de dados
â”‚   â””â”€â”€ dbt_project.yml     # ConfiguraÃ§Ã£o do DBT
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ dag_id=*/           # Logs dos DAGs do Airflow
â”‚   â””â”€â”€ scheduler/          # Logs do scheduler do Airflow
â”œâ”€â”€ plugins/                # Plugins customizados do Airflow
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ scraper.py          # Web scraper do G1
â”‚   â”œâ”€â”€ llm_enricher.py     # Enriquecimento com IA (sentimento/categoria)
â”‚   â””â”€â”€ llm_test_enricher.py # Testes do enriquecimento com IA
â””â”€â”€ streamlit_app/
    â”œâ”€â”€ dashboard.py        # Dashboard original de visualizaÃ§Ã£o
```

## ğŸ› ï¸ Tecnologias Utilizadas

| Componente | Tecnologia | VersÃ£o | Finalidade |
|------------|------------|--------|------------|
| **Linguagem** | ğŸ Python | 3.10+ | Desenvolvimento principal |
| **Web Scraping** | ğŸ­ Playwright | Latest | ConteÃºdo dinÃ¢mico JS |
| **Dados** | ğŸ¼ Pandas | Latest | ManipulaÃ§Ã£o de dados |
| **IA/LLM** | ğŸ¤– OpenAI GPT | 4.0+ | AnÃ¡lise de sentimento e categorizaÃ§Ã£o |
| **OrquestraÃ§Ã£o** | ğŸŒ¬ï¸ Apache Airflow | 2.x | Agendamento e monitoramento |
| **Banco de Dados** | ğŸ˜ PostgreSQL | 15+ | Armazenamento (Bronze Layer) |
| **TransformaÃ§Ã£o** | ğŸ”§ DBT | 1.x | Modelagem (Silver/Gold) |
| **VisualizaÃ§Ã£o** | ğŸ“Š Streamlit | Latest | Dashboard interativo |
| **VisualizaÃ§Ã£o** | ğŸ“ˆ Plotly | Latest | GrÃ¡ficos interativos avanÃ§ados |
| **ContainerizaÃ§Ã£o** | ğŸ³ Docker | Latest | Isolamento de ambiente |
| **OrquestraÃ§Ã£o** | ğŸ™ Docker Compose | Latest | Gerenciamento de containers |

## ğŸ¤ ContribuiÃ§Ã£o

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.

---

*Este projeto demonstra competÃªncias essenciais em Engenharia de Dados: coleta automatizada, orquestraÃ§Ã£o, modelagem de dados e visualizaÃ§Ã£o, utilizando ferramentas padrÃ£o da indÃºstria.*  