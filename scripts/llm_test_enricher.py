import os
import pandas as pd
import logging
from openai import OpenAI
from dotenv import load_dotenv
from sqlalchemy import create_engine, text
import json
from datetime import datetime
import psycopg2

# Configura√ß√£o do logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Debug: Mostrar vers√µes dos pacotes
try:
    import sqlalchemy
    import pandas as pd
    logging.info(f"üîß SQLAlchemy vers√£o: {sqlalchemy.__version__}")
    logging.info(f"üîß Pandas vers√£o: {pd.__version__}")
except:
    pass

def get_postgres_connection():
    """
    Cria uma conex√£o PostgreSQL direta usando psycopg2.
    """
    load_dotenv()
    
    return psycopg2.connect(
        host=os.getenv("POSTGRES_HOST", "localhost"),
        port=os.getenv("POSTGRES_PORT", "5432"),
        database=os.getenv("POSTGRES_DB", "airflow"),
        user=os.getenv("POSTGRES_USER", "airflow"),
        password=os.getenv("POSTGRES_PASSWORD", "airflow")
    )

def test_database_connection(engine):
    """
    Testa a conex√£o com o banco de dados.
    """
    try:
        with engine.connect() as conn:
            result = conn.execute(text("SELECT 1"))
            logging.info("‚úÖ Conex√£o com banco de dados estabelecida com sucesso!")
            return True
    except Exception as e:
        logging.error(f"‚ùå Erro ao conectar com o banco de dados: {e}")
        return False

def check_table_exists(engine, table_name):
    """
    Verifica se a tabela existe no banco.
    """
    try:
        with engine.connect() as conn:
            result = conn.execute(text(f"""
                SELECT EXISTS (
                    SELECT FROM information_schema.tables 
                    WHERE table_name = '{table_name}'
                );
            """))
            exists = result.fetchone()[0]
            if exists:
                logging.info(f"‚úÖ Tabela '{table_name}' encontrada.")
            else:
                logging.warning(f"‚ö†Ô∏è Tabela '{table_name}' n√£o encontrada.")
            return exists
    except Exception as e:
        logging.error(f"‚ùå Erro ao verificar tabela '{table_name}': {e}")
        return False

def create_test_data(engine):
    """
    Cria dados de teste na tabela raw_headlines se ela n√£o existir ou estiver vazia.
    """
    try:
        # Usar begin() para transa√ß√£o autom√°tica
        with engine.begin() as conn:
            # Criar tabela se n√£o existir
            conn.execute(text("""
                CREATE TABLE IF NOT EXISTS raw_headlines (
                    id SERIAL PRIMARY KEY,
                    title TEXT NOT NULL,
                    link TEXT,
                    scraped_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
            """))
            logging.info("‚úÖ Tabela 'raw_headlines' criada/verificada.")
            
            # Verificar se h√° dados
            result = conn.execute(text("SELECT COUNT(*) FROM raw_headlines"))
            count = result.fetchone()[0]
            
            if count == 0:
                logging.info("üìù Inserindo dados de teste...")
                test_headlines = [
                    "Economia brasileira cresce 2.5% no terceiro trimestre",
                    "Nova tecnologia de IA promete revolucionar diagn√≥sticos m√©dicos",
                    "Flamengo vence cl√°ssico e se aproxima do t√≠tulo brasileiro",
                    "Presidente anuncia novo programa de habita√ß√£o popular",
                    "Cientistas descobrem nova esp√©cie na Amaz√¥nia"
                ]
                
                for headline in test_headlines:
                    conn.execute(text("""
                        INSERT INTO raw_headlines (title, link, scraped_at) 
                        VALUES (:title, :link, :scraped_at)
                    """), {
                        "title": headline,
                        "link": f"https://exemplo.com/noticia-{len(headline)}",
                        "scraped_at": datetime.now()
                    })
                logging.info(f"‚úÖ {len(test_headlines)} manchetes de teste inseridas.")
            else:
                logging.info(f"üìä {count} manchetes j√° existem na tabela.")
                
    except Exception as e:
        logging.error(f"‚ùå Erro ao criar dados de teste: {e}")
        raise

def enrich_headlines(db_engine, limit=None, test_mode=True):
    """
    Busca manchetes, enriquece com dados de um LLM e salva na camada Silver.
    Vers√£o compat√≠vel com SQLAlchemy 2.0+
    """
    # Carregar API Key
    load_dotenv()
    api_key = os.getenv("OPENAI_API_KEY")
    
    if not api_key:
        if test_mode:
            logging.warning("‚ö†Ô∏è OPENAI_API_KEY n√£o encontrada. Executando em modo MOCK.")
            client = None
        else:
            logging.error("‚ùå A chave da API da OpenAI (OPENAI_API_KEY) n√£o foi encontrada.")
            raise ValueError("OPENAI_API_KEY n√£o configurada.")
    else:
        client = OpenAI(api_key=api_key)
        logging.info("‚úÖ Cliente OpenAI configurado com sucesso.")
    
    try:
        logging.info("üîç Buscando manchetes da tabela 'raw_headlines' (Bronze)...")
        
        sql_query = "SELECT * FROM raw_headlines"
        if limit:
            sql_query += f" LIMIT {limit}"
        
        # CORRE√á√ÉO: Usar conex√£o PostgreSQL direta com psycopg2
        conn = get_postgres_connection()
        df_raw = pd.read_sql(sql_query, conn)
        conn.close()
        
        if df_raw.empty:
            logging.info("üì≠ Nenhuma manchete encontrada para processar.")
            return
        
        logging.info(f"üì∞ {len(df_raw)} manchetes encontradas para enriquecimento.")

    except Exception as e:
        logging.error(f"‚ùå Erro ao buscar dados do PostgreSQL: {e}")
        return

    # Processar manchetes
    enriched_data = []
    for index, row in df_raw.iterrows():
        headline = row['title']
        logging.info(f"üîÑ Processando manchete ({index + 1}/{len(df_raw)}): {headline[:80]}...")
        
        try:
            if client and not test_mode:
                # Modo real com OpenAI
                prompt = f"""
                Analise a seguinte manchete de not√≠cia e retorne APENAS um objeto JSON com duas chaves: 'sentiment' e 'category'.
                - Para 'sentiment', classifique como "Positiva", "Negativa" ou "Neutra".
                - Para 'category', classifique em uma das seguintes categorias: "Pol√≠tica", "Economia", "Esportes", "Tecnologia", "Cultura", "Sa√∫de", "Internacional", "Justi√ßa", "Outros".

                Manchete: "{headline}"
                """
                
                response = client.chat.completions.create(
                    model="gpt-3.5-turbo-1106",
                    messages=[{"role": "user", "content": prompt}],
                    response_format={"type": "json_object"},
                    temperature=0.0
                )
                
                result = json.loads(response.choices[0].message.content)
                sentiment = result.get('sentiment', 'Erro')
                category = result.get('category', 'Erro')
                
            else:
                # Modo MOCK para testes
                logging.info("üé≠ Usando dados MOCK (sem chamada real para OpenAI)")
                mock_sentiments = ["Positiva", "Negativa", "Neutra"]
                mock_categories = ["Pol√≠tica", "Economia", "Esportes", "Tecnologia", "Cultura"]
                
                sentiment = mock_sentiments[index % len(mock_sentiments)]
                category = mock_categories[index % len(mock_categories)]
            
            enriched_data.append({
                'title': row['title'],
                'link': row['link'],
                'scraped_at': row['scraped_at'],
                'sentiment': sentiment,
                'category': category,
                'processed_at': datetime.now()
            })
            
            logging.info(f"‚úÖ Manchete processada: {sentiment} | {category}")
            
        except Exception as e:
            logging.error(f"‚ùå Erro ao processar a manchete '{headline}': {e}")
            # Adicionar com valores de erro para n√£o perder a manchete
            enriched_data.append({
                'title': row['title'],
                'link': row['link'],
                'scraped_at': row['scraped_at'],
                'sentiment': 'Erro',
                'category': 'Erro',
                'processed_at': datetime.now()
            })
    
    # Salvar dados enriquecidos
    if enriched_data:
        df_enriched = pd.DataFrame(enriched_data)
        logging.info("üíæ Salvando dados enriquecidos na tabela 'silver_enriched_headlines'...")
        
        try:
            # CORRE√á√ÉO: Inser√ß√£o manual usando SQLAlchemy para evitar problemas de compatibilidade
            with db_engine.begin() as conn:
                # Limpar tabela existente
                conn.execute(text("DROP TABLE IF EXISTS silver_enriched_headlines"))
                
                # Criar tabela novamente
                conn.execute(text("""
                    CREATE TABLE silver_enriched_headlines (
                        id SERIAL PRIMARY KEY,
                        title TEXT NOT NULL,
                        link TEXT,
                        scraped_at TIMESTAMP,
                        sentiment VARCHAR(20),
                        category VARCHAR(50),
                        processed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    );
                """))
                
                # Inserir dados um por um
                for _, row in df_enriched.iterrows():
                    conn.execute(text("""
                        INSERT INTO silver_enriched_headlines 
                        (title, link, scraped_at, sentiment, category, processed_at) 
                        VALUES (:title, :link, :scraped_at, :sentiment, :category, :processed_at)
                    """), {
                        "title": row['title'],
                        "link": row['link'], 
                        "scraped_at": row['scraped_at'],
                        "sentiment": row['sentiment'],
                        "category": row['category'],
                        "processed_at": row['processed_at']
                    })
            
            logging.info("üéâ Processo de enriquecimento conclu√≠do com sucesso!")
            logging.info(f"üìä {len(enriched_data)} manchetes processadas e salvas.")
            
            # Mostrar algumas amostras
            logging.info("üìã Primeiras 3 manchetes processadas:")
            for i, row in df_enriched.head(3).iterrows():
                logging.info(f"   ‚Ä¢ {row['title'][:60]}... | {row['sentiment']} | {row['category']}")
                
        except Exception as e:
            logging.error(f"‚ùå Erro ao salvar dados enriquecidos: {e}")
    else:
        logging.warning("‚ö†Ô∏è Nenhum dado foi enriquecido com sucesso.")

def run_comprehensive_test():
    """
    Executa um teste abrangente do pipeline.
    """
    logging.info("üöÄ Iniciando teste abrangente do pipeline de enriquecimento...")
    
    load_dotenv()
    
    # Configura√ß√µes do banco de dados
    DB_HOST = os.getenv("POSTGRES_HOST", "localhost")
    DB_PORT = os.getenv("POSTGRES_PORT", "5432")
    DB_NAME = os.getenv("POSTGRES_DB", "airflow")
    DB_USER = os.getenv("POSTGRES_USER", "airflow")
    DB_PASSWORD = os.getenv("POSTGRES_PASSWORD", "airflow")
    
    # String de conex√£o
    connection_string = f"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}"
    
    try:
        # Criar engine do banco de dados
        logging.info("üîó Criando conex√£o com o banco de dados PostgreSQL...")
        engine = create_engine(connection_string, echo=False)  # echo=False para menos logs
        
        # Teste 1: Conex√£o
        logging.info("\nüì° TESTE 1: Verificando conex√£o com banco...")
        if not test_database_connection(engine):
            return False
        
        # Teste 2: Verificar/Criar tabelas
        logging.info("\nüìã TESTE 2: Verificando estrutura das tabelas...")
        check_table_exists(engine, "raw_headlines")
        create_test_data(engine)
        
        # Teste 3: API OpenAI (opcional)
        logging.info("\nü§ñ TESTE 3: Verificando API OpenAI...")
        api_key = os.getenv("OPENAI_API_KEY")
        if api_key:
            try:
                client = OpenAI(api_key=api_key)
                # Teste simples
                response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[{"role": "user", "content": "Responda apenas: OK"}],
                    max_tokens=10
                )
                logging.info("‚úÖ API OpenAI funcionando corretamente.")
                test_mode = False
            except Exception as e:
                logging.warning(f"‚ö†Ô∏è API OpenAI n√£o est√° funcionando: {e}")
                logging.info("üé≠ Continuando em modo MOCK...")
                test_mode = True
        else:
            logging.info("üé≠ OPENAI_API_KEY n√£o configurada. Usando modo MOCK.")
            test_mode = True
        
        # Teste 4: Enriquecimento
        logging.info("\nüéØ TESTE 4: Executando enriquecimento...")
        enrich_headlines(engine, limit=5, test_mode=test_mode)
        
        # Teste 5: Verificar resultados detalhadamente
        logging.info("\nüìä TESTE 5: Verificando resultados salvos...")
        with engine.connect() as conn:
            result = conn.execute(text("SELECT COUNT(*) FROM silver_enriched_headlines"))
            count = result.fetchone()[0]
            logging.info(f"üìä Total de registros processados: {count}")
            
            if count == 0:
                logging.warning("‚ö†Ô∏è Nenhum dado foi processado!")
                return False
            
            # Buscar todos os dados para an√°lise
            conn = get_postgres_connection()
            df_enriched = pd.read_sql(
                "SELECT * FROM silver_enriched_headlines ORDER BY id", 
                conn
            )
            conn.close()
            
            # Mostrar cada manchete processada em detalhes
            logging.info("\nüì∞ AN√ÅLISE DETALHADA DAS MANCHETES PROCESSADAS:")
            logging.info("=" * 80)
            
            for i, row in df_enriched.iterrows():
                logging.info(f"\nüî∏ MANCHETE {i+1}:")
                logging.info(f"   üì∞ T√≠tulo: {row['title']}")
                logging.info(f"   üîó Link: {row['link']}")
                logging.info(f"   üé≠ Sentimento: {row['sentiment']}")
                logging.info(f"   üìÇ Categoria: {row['category']}")
                if 'processed_at' in row:
                    logging.info(f"   ‚è∞ Processado em: {row['processed_at']}")
                logging.info("   " + "-" * 60)
            
            # Estat√≠sticas resumidas
            logging.info(f"\nüìà ESTAT√çSTICAS DA AN√ÅLISE:")
            logging.info("=" * 50)
            
            # Distribui√ß√£o de sentimentos
            sentiment_counts = df_enriched['sentiment'].value_counts()
            logging.info("üé≠ DISTRIBUI√á√ÉO DE SENTIMENTOS:")
            for sentiment, count in sentiment_counts.items():
                percentage = (count / len(df_enriched)) * 100
                logging.info(f"   ‚Ä¢ {sentiment}: {count} ({percentage:.1f}%)")
            
            # Distribui√ß√£o de categorias
            category_counts = df_enriched['category'].value_counts()
            logging.info("\nüìÇ DISTRIBUI√á√ÉO DE CATEGORIAS:")
            for category, count in category_counts.items():
                percentage = (count / len(df_enriched)) * 100
                logging.info(f"   ‚Ä¢ {category}: {count} ({percentage:.1f}%)")
            
            # Verificar se h√° erros no processamento
            error_sentiment = df_enriched[df_enriched['sentiment'] == 'Erro'].shape[0]
            error_category = df_enriched[df_enriched['category'] == 'Erro'].shape[0]
            
            if error_sentiment > 0 or error_category > 0:
                logging.warning(f"‚ö†Ô∏è ATEN√á√ÉO: {error_sentiment} erros de sentimento e {error_category} erros de categoria detectados!")
            else:
                logging.info("‚úÖ Todos os dados foram processados sem erros!")
        
        logging.info("\nüéâ VERIFICA√á√ÉO CONCLU√çDA COM SUCESSO!")
        return True
        
    except Exception as e:
        logging.error(f"‚ùå Erro ao verificar dados enriquecidos: {e}")
        return False
        
    except Exception as e:
        logging.error(f"‚ùå Erro durante os testes: {e}")
        logging.error(f"   Tipo do erro: {type(e).__name__}")
        return False

def create_tables_if_not_exist(engine):
    """
    Cria as tabelas necess√°rias se elas n√£o existirem.
    """
    try:
        with engine.begin() as conn:
            # Criar tabela bronze (raw_headlines)
            conn.execute(text("""
                CREATE TABLE IF NOT EXISTS raw_headlines (
                    id SERIAL PRIMARY KEY,
                    title TEXT NOT NULL,
                    link TEXT,
                    scraped_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
            """))
            
            # Criar tabela silver (enriched_headlines)
            conn.execute(text("""
                CREATE TABLE IF NOT EXISTS silver_enriched_headlines (
                    id SERIAL PRIMARY KEY,
                    title TEXT NOT NULL,
                    link TEXT,
                    scraped_at TIMESTAMP,
                    sentiment VARCHAR(20),
                    category VARCHAR(50),
                    processed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
            """))
            
            logging.info("‚úÖ Estrutura das tabelas verificada/criada.")
            
    except Exception as e:
        logging.error(f"‚ùå Erro ao criar tabelas: {e}")
        raise

def main():
    """
    Fun√ß√£o principal para execu√ß√£o dos testes.
    """
    print("=" * 70)
    print("üß™ TESTE DO PIPELINE DE ENRIQUECIMENTO DE HEADLINES")
    print("=" * 70)
    
    # Verificar vari√°veis de ambiente
    load_dotenv()
    required_vars = ["POSTGRES_HOST", "POSTGRES_DB", "POSTGRES_USER", "POSTGRES_PASSWORD"]
    missing_vars = [var for var in required_vars if not os.getenv(var)]
    
    if missing_vars:
        logging.error(f"‚ùå Vari√°veis de ambiente faltando: {missing_vars}")
        logging.error("   Certifique-se de que o arquivo .env est√° configurado corretamente.")
        return
    
    # Configura√ß√µes do banco de dados
    DB_HOST = os.getenv("POSTGRES_HOST", "localhost")
    DB_PORT = os.getenv("POSTGRES_PORT", "5432")
    DB_NAME = os.getenv("POSTGRES_DB", "airflow")
    DB_USER = os.getenv("POSTGRES_USER", "airflow")
    DB_PASSWORD = os.getenv("POSTGRES_PASSWORD", "airflow")
    
    logging.info(f"üîß Configura√ß√µes do banco:")
    logging.info(f"   Host: {DB_HOST}:{DB_PORT}")
    logging.info(f"   Database: {DB_NAME}")
    logging.info(f"   User: {DB_USER}")
    
    # String de conex√£o
    connection_string = f"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}"
    
    try:
        # Criar engine do banco de dados
        engine = create_engine(connection_string, echo=False)
        
        # Criar tabelas se necess√°rio
        create_tables_if_not_exist(engine)
        
        # Executar testes
        success = run_comprehensive_test()
        
        if success:
            print("\n" + "=" * 70)
            print("üéâ PIPELINE TESTADO COM SUCESSO!")
            print("   Agora voc√™ pode criar sua DAG do Airflow com confian√ßa.")
            print("=" * 70)
        else:
            print("\n" + "=" * 70)
            print("‚ùå TESTES FALHARAM!")
            print("   Verifique os logs acima para identificar problemas.")
            print("=" * 70)
            
    except Exception as e:
        logging.error(f"‚ùå Erro cr√≠tico: {e}")
        print("\n" + "=" * 70)
        print("üí• ERRO CR√çTICO NO TESTE!")
        print(f"   {e}")
        print("=" * 70)

if __name__ == "__main__":
    main()